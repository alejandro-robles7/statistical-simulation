{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling methods\n",
    "\n",
    "In this chapter, we will get a brief introduction to resampling methods and their applications. We will get a taste of bootstrap resampling, jackknife resampling, and permutation testing. After completing this chapter, students will be able to start applying simple resampling methods for data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why resample?\n",
    "\n",
    "### Advantages\n",
    "- Simple implementation procedure\n",
    "- Applicable to complex estimators\n",
    "- No string assumpions\n",
    "\n",
    "### Drawbacks\n",
    "- Computationally expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability example\n",
    "In this exercise, we will review the difference between sampling with and without replacement. We will calculate the probability of an event using simulation, but vary our sampling method to see how it impacts probability.\n",
    "\n",
    "Consider a bowl filled with colored candies - three blue, two green, and five yellow. Draw three candies at random, with replacement and without replacement. You want to know the probability of drawing a yellow candy on the third draw given that the first candy was blue and the second candy was green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability with replacement = 0.0266, without replacement = 0.0415\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize seed and parameters\n",
    "np.random.seed(123)\n",
    "\n",
    "# Set up the bowl\n",
    "success_rep, success_no_rep, sims = 0, 0, 10000\n",
    "bowl = ['b'] * 3 + ['g'] * 2 + ['y'] * 5\n",
    "\n",
    "for i in range(sims):\n",
    "    # Sample with and without replacement & increment success counters\n",
    "    sample_rep = np.random.choice(bowl, size=3, replace=True)\n",
    "    sample_no_rep = np.random.choice(bowl, size=3, replace=False )\n",
    "    if (sample_rep[0] == 'b') & (sample_rep[1] == 'g') & (sample_rep[2] == 'y'): \n",
    "        success_rep += 1\n",
    "    if (sample_no_rep[0] == 'b') & (sample_no_rep[1] == 'g') & (sample_no_rep[2] == 'y'): \n",
    "        success_no_rep += 1\n",
    "\n",
    "# Calculate probabilities\n",
    "prob_with_replacement = success_rep / sims\n",
    "prob_without_replacement = success_no_rep / sims\n",
    "print(\"Probability with replacement = {}, without replacement = {}\".format(prob_with_replacement, prob_without_replacement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a simple bootstrap\n",
    "Welcome to the first exercise in the bootstrapping section. We will work through an example where we learn to run a simple bootstrap. As we saw in the video, the main idea behind bootstrapping is sampling with replacement.\n",
    "\n",
    "Suppose you own a factory that produces wrenches. You want to be able to characterize the average length of the wrenches and ensure that they meet some specifications. Your factory produces thousands of wrenches every day, but it's infeasible to measure the length of each wrench. However, you have access to a representative sample of 100 wrenches. Let's use bootstrapping to get the 95% confidence interval (CI) for the average lengths.\n",
    "\n",
    "Examine the list wrench_lengths, which has 100 observed lengths of wrenches, in the shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped Mean Length = 10.026453646284399, 95% CI = [ 9.78529006 10.26304294]\n"
     ]
    }
   ],
   "source": [
    "from data.chap1_data import wrench_lengths\n",
    "\n",
    "# Draw some random sample with replacement and append mean to mean_lengths.\n",
    "mean_lengths, sims = [], 1000\n",
    "for i in range(sims):\n",
    "    temp_sample = np.random.choice(wrench_lengths, replace=True, size=len(wrench_lengths))\n",
    "    sample_mean = temp_sample.mean()\n",
    "    mean_lengths.append(sample_mean)\n",
    "    \n",
    "# Calculate bootstrapped mean and 95% confidence interval.\n",
    "boot_mean = np.mean(mean_lengths)\n",
    "boot_95_ci = np.percentile(mean_lengths, [2.5, 97.5])\n",
    "print(\"Bootstrapped Mean Length = {}, 95% CI = {}\".format(boot_mean, boot_95_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-standard estimators\n",
    "In the last exercise, you ran a simple bootstrap that we will now modify for more complicated estimators.\n",
    "\n",
    "Suppose you are studying the health of students. You are given the height and weight of 1000 students and are interested in the median height as well as the correlation between height and weight and the associated 95% CI for these quantities. Let's use bootstrapping.\n",
    "\n",
    "Examine the pandas DataFrame df with the heights and weights of 1000 students. Using this, calculate the 95% CI for both the median height as well as the correlation between height and weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height Median CI = [5.25485527 5.56904469] \n",
      "Height Weight Correlation CI = [0.93868267 0.95092012]\n"
     ]
    }
   ],
   "source": [
    "from data.chap1_data import student_data\n",
    "from pandas import DataFrame\n",
    "\n",
    "df = DataFrame(student_data)\n",
    "\n",
    "# Sample with replacement and calculate quantities of interest\n",
    "sims, data_size, height_medians, hw_corr = 1000, df.shape[0], [], []\n",
    "for i in range(sims):\n",
    "    tmp_df = df.sample(n=data_size, replace=True)\n",
    "    height_medians.append(tmp_df.heights.median())\n",
    "    hw_corr.append(tmp_df.weights.corr(tmp_df.heights))\n",
    "\n",
    "# Calculate confidence intervals\n",
    "height_median_ci = np.percentile(height_medians, [2.5, 97.5])\n",
    "height_weight_corr_ci = np.percentile(hw_corr, [2.5, 97.5])\n",
    "print(\"Height Median CI = {} \\nHeight Weight Correlation CI = {}\".format( height_median_ci, height_weight_corr_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping regression\n",
    "Now let's see how bootstrapping works with regression. Bootstrapping helps estimate the uncertainty of non-standard estimators. Consider the $R^2$ statistic associated with a regression. When you run a simple least squares regression, you get a value for $R^2$. But let's see how can we get a 95% CI for $R^2$.\n",
    "\n",
    "Examine the DataFrame df with a dependent variable y and two independent variables $X1$ and $X2$ using df.head(). We've already fit this regression with statsmodels (sm) using:\n",
    "\n",
    "reg_fit = sm.OLS(df['y'], df.iloc[:,1:]).fit()\n",
    "\n",
    "Examine the result using reg_fit.summary() to find that $R^2=0.3504$. Use bootstrapping to calculate the 95% CI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared 95% CI = [0.31260621 0.40561087]\n"
     ]
    }
   ],
   "source": [
    "from data.chap1_data import regression_data\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "df = DataFrame(regression_data)\n",
    "\n",
    "rsquared_boot, coefs_boot, sims = [], [], 1000\n",
    "reg_fit = OLS(df['y'], df[['Intercept', 'X1', 'X2']]).fit()\n",
    "\n",
    "# Run 1K iterations\n",
    "for i in range(sims):\n",
    "    # First create a bootstrap sample with replacement with n=df.shape[0]\n",
    "    bootstrap = df.sample(n=df.shape[0], replace=True)\n",
    "    # Fit the regression and append the r square to rsquared_boot\n",
    "    rsquared_boot.append(OLS(bootstrap['y'],bootstrap[['Intercept', 'X1', 'X2']]).fit().rsquared)\n",
    "\n",
    "# Calculate 95% CI on rsquared_boot\n",
    "r_sq_95_ci = np.percentile(rsquared_boot, [2.5, 97.5])\n",
    "print(\"R Squared 95% CI = {}\".format(r_sq_95_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic jackknife estimation - mean\n",
    "Jackknife resampling is an older procedure, which isn't used as often compared as bootstrapping. However, it's still useful to know how to run a basic jackknife estimation procedure. In this first exercise, we will calculate the jackknife estimate for the mean. Let's return to the wrench factory.\n",
    "\n",
    "You own a wrench factory and want to measure the average length of the wrenches to ensure that they meet some specifications. Your factory produces thousands of wrenches every day, but it's infeasible to measure the length of each wrench. However, you have access to a representative sample of 100 wrenches. Let's use jackknife estimation to get the average lengths.\n",
    "\n",
    "Examine the variable wrench_lengths in the shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackknife estimate of the mean = 10.027109074099998\n"
     ]
    }
   ],
   "source": [
    "# Leave one observation out from wrench_lengths to get the jackknife sample and store the mean length\n",
    "mean_lengths, n = [], len(wrench_lengths)\n",
    "index = np.arange(n)\n",
    "wrench_lengths = np.array(wrench_lengths)\n",
    "\n",
    "for i in range(n):\n",
    "    jk_sample = wrench_lengths[index != i]\n",
    "    mean_lengths.append(jk_sample.mean())\n",
    "\n",
    "# The jackknife estimate is the mean of the mean lengths from each sample\n",
    "mean_lengths_jk = np.mean(np.array(mean_lengths))\n",
    "print(\"Jackknife estimate of the mean = {}\".format(mean_lengths_jk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jackknife confidence interval for the median\n",
    "In this exercise, we will calculate the jackknife 95% CI for a non-standard estimator. Here, we will look at the median. Keep in mind that the variance of a jackknife estimator is n-1 times the variance of the individual jackknife sample estimates where n is the number of observations in the original sample.\n",
    "\n",
    "Returning to the wrench factory, you are now interested in estimating the median length of the wrenches along with a 95% CI to ensure that the wrenches are within tolerance.\n",
    "\n",
    "Let's revisit the code from the previous exercise, but this time in the context of median lengths. By the end of this exercise, you will have a much better idea of how to use jackknife resampling to calculate confidence intervals for non-standard estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackknife 95% CI lower = 9.138592415216381, upper = 10.754868124783625\n"
     ]
    }
   ],
   "source": [
    "# Leave one observation out to get the jackknife sample and store the median length\n",
    "median_lengths = []\n",
    "for i in range(n):\n",
    "    jk_sample = wrench_lengths[index != i]\n",
    "    median_lengths.append(np.median(jk_sample))\n",
    "\n",
    "median_lengths = np.array(median_lengths)\n",
    "\n",
    "# Calculate jackknife estimate and it's variance\n",
    "jk_median_length = median_lengths.mean()\n",
    "jk_var = (n-1)*np.var(median_lengths)\n",
    "\n",
    "# Assuming normality, calculate lower and upper 95% confidence intervals\n",
    "jk_lower_ci = jk_median_length - 1.96 * np.sqrt(jk_var)\n",
    "jk_upper_ci = jk_median_length + 1.96 * np.sqrt(jk_var)\n",
    "print(\"Jackknife 95% CI lower = {}, upper = {}\".format(jk_lower_ci, jk_upper_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a single permutation\n",
    "In the next few exercises, we will run a significance test using permutation testing. As discussed in the video, we want to see if there's any difference in the donations generated by the two designs - A and B. Suppose that you have been running both the versions for a few days and have generated 500 donations on A and 700 donations on B, stored in the variables donations_A and donations_B.\n",
    "\n",
    "We first need to generate a null distribution for the difference in means. We will achieve this by generating multiple permutations of the dataset and calculating the difference in means for each case.\n",
    "\n",
    "First, let's generate one permutation and calculate the difference in means for the permuted dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in the permuted mean values = 0.009754644303140658.\n"
     ]
    }
   ],
   "source": [
    "from data.chap1_data import donations_A, donations_B\n",
    "\n",
    "# Concatenate the two arrays donations_A and donations_B into data\n",
    "len_A, len_B = len(donations_A), len(donations_B)\n",
    "data = np.concatenate([donations_A, donations_B])\n",
    "\n",
    "# Get a single permutation of the concatenated length\n",
    "perm = np.random.permutation(len(donations_A) + len(donations_B))\n",
    "\n",
    "# Calculate the permutated datasets and difference in means\n",
    "permuted_A = data[perm[:len(donations_A)]]\n",
    "permuted_B = data[perm[len(donations_A):]]\n",
    "diff_in_means = permuted_A.mean() - permuted_B.mean()\n",
    "print(\"Difference in the permuted mean values = {}.\".format(diff_in_means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing - Difference of means\n",
    "We want to test the hypothesis that there is a difference in the average donations received from A and B. Previously, you learned how to generate one permutation of the data. Now, we will generate a null distribution of the difference in means and then calculate the p-value.\n",
    "\n",
    "For the null distribution, we first generate multiple permuted datasets and store the difference in means for each case. We then calculate the test statistic as the difference in means with the original dataset. Finally, we calculate the p-value as twice the fraction of cases where the difference is greater than or equal to the absolute value of the test statistic (2-sided hypothesis). A p-value of less than say 0.05 could then determine statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 0.002\n"
     ]
    }
   ],
   "source": [
    "reps = 1000\n",
    "donations_A, donations_B = np.array(donations_A), np.array(donations_B)\n",
    "\n",
    "# Generate permutations equal to the number of repetitions\n",
    "perm = np.array([np.random.permutation(len(donations_A) + len(donations_B)) for i in range(reps)])\n",
    "permuted_A_datasets = data[perm[:, :len(donations_A)]]\n",
    "permuted_B_datasets = data[perm[:, len(donations_A):]]\n",
    "\n",
    "# Calculate the difference in means for each of the datasets\n",
    "samples = permuted_A_datasets.mean(axis=1) - permuted_B_datasets.mean(axis=1)\n",
    "\n",
    "# Calculate the test statistic and p-value\n",
    "test_stat = donations_A.mean() - donations_B.mean()\n",
    "p_val = 2*np.sum(samples >= np.abs(test_stat))/reps\n",
    "print(\"p-value = {}\".format(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing - Non-standard statistics\n",
    "In the previous two exercises, we ran a permutation test for the difference in mean values. Now let's look at non-standard statistics.\n",
    "\n",
    "Suppose that you're interested in understanding the distribution of the donations received from websites A and B. For this, you want to see if there's a statistically significant difference in the median and the 80th percentile of the donations. Permutation testing gives you a wonderfully flexible framework for attacking such problems.\n",
    "\n",
    "Let's go through running a test to see if there's a difference in the median and the 80th percentile of the distribution of donations. As before, you're given the donations from the websites A and B in the variables donations_A and donations_B respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80th Percentile: test statistic = 1.6951624520000035, p-value = 0.034\n",
      "Median: test statistic = 0.6434965699999999, p-value = 0.012\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference in 80th percentile and median for each of the permuted datasets (A and B)\n",
    "samples_percentile = np.percentile(permuted_A_datasets, 80, axis=1) - np.percentile(permuted_B_datasets, 80, axis=1)\n",
    "samples_median = np.median(permuted_A_datasets, axis=1) - np.median(permuted_B_datasets, axis=1)\n",
    "\n",
    "# Calculate the test statistic from the original dataset and corresponding p-values\n",
    "test_stat_percentile = np.percentile(donations_A, 80) - np.percentile(donations_B, 80)\n",
    "test_stat_median = np.median(donations_A) - np.median(donations_B)\n",
    "p_val_percentile = 2*np.sum(samples_percentile >= np.abs(test_stat_percentile))/reps\n",
    "p_val_median = 2*np.sum(samples_median >= np.abs(test_stat_median))/reps\n",
    "\n",
    "print(\"80th Percentile: test statistic = {}, p-value = {}\".format(test_stat_percentile, p_val_percentile))\n",
    "print(\"Median: test statistic = {}, p-value = {}\".format(test_stat_median, p_val_median))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
